{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Assignment 4</h1>\n",
    "<h2> Support Vector Machine </h2>\n",
    "<br>\n",
    "<p>Apply the Scikit Learn SVM Classifier to the Iris dataset using all three categories and all four features at once.\n",
    "<br>Run the SVM model (at least) four times using a different kernel each time. Compare and discuss the results for each of the kernels.</p></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Iris data set\n",
    "iris = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# currently iris has columns names '0'-'4'. We want meaningful names,\n",
    "# so we will change it.\n",
    "iris.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Split data into training and testing sets</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: everything except the 'species' column\n",
    "X = iris.drop('species', axis = 1)\n",
    "\n",
    "# what are we trying to predict?\n",
    "y = iris['species']\n",
    "\n",
    "#split data. We will use 30% of data to train the model and 70% to test it\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.6, random_state=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Scaling data</h3>\n",
    "<p>According to the https://scikit-learn.org/ \"it is highly recommended to scale your data\" because Support Vector Machine algorithms are not scale invariant. Main purpose of scaling data before processing is to avoid attributes in greater numeric ranges. Iris data doesn't really have attributes in greater numeric ranges, so probably we could skip scaling. We did it for sake of practicing.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We scale the data in the range [-1,1]\n",
    "scaling = MinMaxScaler(feature_range=(-1, 1)).fit(X_train)\n",
    "X_train = scaling.transform(X_train)\n",
    "X_test = scaling.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Train a model</h3>\n",
    "<p> We will check how using different kernels influences accuracy of the model. We will consider Radial Basis Function kernel, linear kernel, polynomial of degrees 2,3, and sigmoid kernel.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (svm.SVC(kernel='rbf'),\n",
    "          svm.SVC(kernel='sigmoid'),\n",
    "          svm.SVC(kernel='poly', degree=2, gamma='auto'),\n",
    "          svm.SVC(kernel='poly', degree=3, gamma='auto'),\n",
    "          svm.SVC(kernel='linear'))\n",
    "\n",
    "titles = ['rbf',\n",
    "          'sigmoid',\n",
    "          'poly (deg.2)',\n",
    "          'poly (deg.3)',\n",
    "          'linear']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Cross-validation </h3>\n",
    "<p> In order to avoid overfitting, another part of the dataset can be held out as a “validation set”, which reduces number of samples which can be used for learning the model. That is why we can use k-fold cross-validation. This can be computationally expensive, but solves the problem of reducing samples number, which is important for a small data set like Iris.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mKernel                                  CV accuracy score   Test accuracy score \u001b[0;0m\n",
      "\n",
      "rbf                                       0.933333            0.966667\n",
      "sigmoid                                   0.950000            0.955556\n",
      "poly (deg.2)                              0.666667            0.588889\n",
      "poly (deg.3)                              0.750000            0.611111\n",
      "linear                                    0.933333            0.966667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1635d23f3c8>,\n",
       "  <matplotlib.axis.XTick at 0x1635d239548>,\n",
       "  <matplotlib.axis.XTick at 0x1635d233608>,\n",
       "  <matplotlib.axis.XTick at 0x1635d2732c8>,\n",
       "  <matplotlib.axis.XTick at 0x1635d278a48>],\n",
       " <a list of 5 Text xticklabel objects>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# text format \n",
    "bold_start = \"\\033[1m\"\n",
    "bold_end = \"\\033[0;0m\"\n",
    "\n",
    "print(bold_start + \"{:40}{:20}{:20}\".format('Kernel', 'CV accuracy score', 'Test accuracy score') + bold_end+ '\\n')   \n",
    "accuracy = []\n",
    "for i, model in enumerate(models):\n",
    "    cv_performance = cross_val_score(model, X_train, y_train,cv=10)\n",
    "    test_performance = model.fit(X_train, y_train).score(X_test,y_test)\n",
    "    accuracy.append(test_performance)\n",
    "    print (\"{:40}{:10f}{:20f}\".format(titles[i], np.mean(cv_performance),test_performance))\n",
    "    \n",
    "#visualize\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize = (8,4))\n",
    "ax.set_xlabel('Kernel')\n",
    "ax.set_ylabel('Test accuracy score')\n",
    "ax.set_title(\"Test accuracy score for different kernels\", fontsize ='medium')\n",
    "y_pos = np.arange(len(titles))\n",
    "ax.bar(y_pos,accuracy, label='train')\n",
    "plt.xticks(y_pos, titles)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> We notice that the models worked out really good except for the polynomial kernels.<br><br>\n",
    "Because the data set is pretty small we can use Gram matrix of all possible inner products of vectors set to find optimal kernel (this information was taken from Udemy Data Science course).</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Look for better parameters</h3>\n",
    "We can search for the best combinations of kernels and parameters (like C and gamma) using grid_search.\n",
    "During the search, the code tests different combinations of linear and RBF together with C and gamma parameters. C is important because it controls the cost of misclassification of training data. A large C value gives low bias (because we penalize the cost of misclassification a lot) and large variance, therefore it creates a larger-margin hyperplane.\n",
    "Large Gamma leads to small variance and large bias. A lower value of Gamma will loosely fit the training dataset, whereas a higher value of gamma will exactly fit the training dataset, which causes over-fitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'C': 10, 'kernel': 'linear'}\n",
      "Cross-validation accuracy score: 0.950, test accuracy score: 0.967\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "learning_algo = svm.SVC(kernel='linear', random_state=101)\n",
    "\n",
    "search_space = [{'kernel': ['linear'], 'C': [1, 10, 100, 1000]},\n",
    "                {'kernel': ['rbf'], 'C': [1, 10, 100, 1000], 'gamma': [0, 0.1, 0.01, 0.001, 0.0001]},\n",
    "                {'kernel': ['sigmoid'], 'C': [1, 10, 100, 1000], 'gamma': [0, 0.1, 0.01, 0.001, 0.0001]},\n",
    "                {'kernel': ['poly'], 'C': [1, 10, 100, 1000], 'gamma': [0, 0.1, 0.01, 0.001, 0.0001], 'degree':[1,2,3,4,5]}]\n",
    "\n",
    "gridsearch = GridSearchCV(learning_algo, param_grid=search_space, refit=True, cv=10)\n",
    "gridsearch.fit(X_train,y_train)\n",
    "print ('Best parameter: '+ str(gridsearch.best_params_))\n",
    "\n",
    "cv_performance = gridsearch.best_score_\n",
    "test_performance = gridsearch.score(X_test, y_test)\n",
    "\n",
    "print ('Cross-validation accuracy score: %0.3f,'\n",
    "' test accuracy score: %0.3f'\n",
    "% (cv_performance,test_performance))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result of best kernel/parameters search we came to the conclusion that linear kernel works the best for this data. However, RBF demonstrates extremely close accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Can we improve poly kernel performance? </h3>\n",
    "We can try to find parameters C, gamma, and degree for polynomial kernel such that they give better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameter: {'C': 1000, 'degree': 3, 'gamma': 0.1, 'kernel': 'poly'}\n",
      "\n",
      "\u001b[1mCross-validation accuracy score: 0.933, test accuracy score: 0.933\u001b[0;0m\n"
     ]
    }
   ],
   "source": [
    "learning_algo = svm.SVC(kernel='linear', random_state=101)\n",
    "\n",
    "search_space = [{'kernel': ['poly'], 'C': [1, 10, 100, 1000], \n",
    "                 'gamma': [0, 0.1, 0.01, 0.001, 0.0001], \n",
    "                 'degree':[2,3,4,5]}]\n",
    "\n",
    "gridsearch = GridSearchCV(learning_algo, param_grid=search_space, refit=True, cv=10)\n",
    "gridsearch.fit(X_train,y_train)\n",
    "print ('Best parameter: '+ str(gridsearch.best_params_))\n",
    "\n",
    "cv_performance = gridsearch.best_score_\n",
    "test_performance = gridsearch.score(X_test, y_test)\n",
    "\n",
    "print ('\\n'+ bold_start+'Cross-validation accuracy score: %0.3f,'\n",
    "' test accuracy score: %0.3f'\n",
    "% (cv_performance,test_performance)+bold_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result we got 93.3% test accuracy when gamma is small and C is large. Large Value of parameter C => small margin. Larger C values will take more time to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Summary </h2><br><br>\n",
    "We analyzed iris data using support vector machine and different kernels.The special capability of kernel functions is to\n",
    "map the original feature space into a new feature space reconstructed to achieve better classification of results. It’s similar to the polynomial expansion principle, but the mathematics behind it require fewer computations, allowing the algorithm to map complex response functions in less time and with more precision (\"Machine Learning for Dummies\" by J.Nueller and L.Massaron).<br><br>\n",
    "We chose to use Radial Basis Function, linear, polynomial of degrees 2 and 3, and sigmoid kernels. As a result, after scaling data, cross-validation, and fitting data we figured that two most effective kernels for this data set are linear and RBF (accuracy 96.7%). Sigmoid function also gave us a good result of 95.5%. However, polynomial functions resulted in a low accuracy of 58.8% fir degree 2, and 61.1% for degree 3.<br><br>\n",
    "After we analyzed models with default parameters, we decided to find out if there are other parameters of C, gamma, and degree which can lead to a better performance. So, we used grid_search and checked combinations of kernels and C, gamma, and degree parameters. Parameter C=10 for linear kernel worked the best for Iris data giving accuracy of 96.7%. So, we were not able to improve already high accuracy.<br><br>\n",
    "However, we tried to improve accuracy of the polynomial kernel models and we again implemented grid_search for only polynomial kernel. As a result we were able to significally improve accuracy from 61.1% to 93.3% for polynomial of degree 3. We were able to get this result by using C = 100 and gamma = 0.1. \n",
    "Large Value of parameter C => small margin. Larger C values will take more time to train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
